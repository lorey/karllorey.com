{"pageProps":{"post":{"title":"Keeping Pandas DataFrames clean when importing JSON (with Context Managers)","slug":"keeping-pandas-dataframes-clean-importing-json","date":"2019-03-03T09:30:13.000Z","tags":"Machine Learning, Pandas, Clean Code, Python, Tech","category":"Tech","link":null,"description":null,"type":"text","content":"\nFor work, I do a lot of data analysis to find the most promising young startups.\nAs a first step, you always have to import the desired data into a Pandas DataFrame\nand do some preprocessing, for example by importing JSON data from some API. \nWhen doing this kind of pre-processing,\nyou usually have a lot of temporary columns in your DataFrame that get imported but need to be dropped later in the process.\nTo deal with these temporary columns,\nI built a custom Context Manager that keeps track of all imported columns\nand deletes them when you're done.\nThis way, your code stays lean and you don't have to remove temporary columns yourself.\nIn this short article, I will show how you can keep your pre-processing clean\nand use a Python ContextManager to clean up temporary columns.\n\nIn this example I will use the actual code I use for importing data from the API of our CRM named Hubspot.\nWhat I retrieve is a list of companies stored as a list of Python dictionaries.\nTo import a list of dictionaries in pandas you basically do:\n\n```python\nfrom pandas.io.json import json_normalize\n\ndf = json_normalize(data)\n```\n\nThe json_normalize function generates a clean DataFrame based on the given `data` parameter and normalizes the hierarchy so you get clean column names.\nThis is especially useful for nested dictionaries.\n\n## Ugly: Keeping imported columns\n\nThe problem with json_normalize is that you usually only want a subset of the imported columns,\nmostly with different names or some kind of pre-processing, too.\nSo you might be tempted to do something like this:\n\n```python\nfrom pandas.io.json import json_normalize\n\ndf = json_normalize(data)\n\ndf['company_id'] = df['companyId']\ndf['location'] = df['properties.city.value']\ndf['name'] = df['properties.name.value']\ndf['domain'] = df['properties.website.value']\n//..apply(), .as_type(int), whatever...\n```\n\nThis works, but keeps all the imported columns inplace and might take a lot of storage.\nSo what can you do?\n\n## Ugly: Dropping columns manually\n\nSo after importing, you want to get rid of all temporary columns from the import.\nTo do this, you have to either select the columns you want or drop all columns you don't want.\nIn both cases, you have to somehow keep track of the temporary columns or the ones you want to keep.\nTo deal with this, one solution would be to prefix temporary columns and delete them afterwards:\n\n```python\nfrom pandas.io.json import json_normalize\n\ndf = json_normalize(data)\n\n// make temporary columns\ndf.columns = ['temp_' + c for c in df.columns]\n\n// pre-processing, basic calculations, etc.\ndf['company_id'] = df['temp_companyId']\ndf['location'] = df['temp_properties.city.value']\ndf['name'] = df['temp_properties.name.value']\ndf['domain'] = df['temp_properties.website.value']\n//..apply(), .as_type(int), whatever...\n```\n\nAfterwards, you would then select all desired columns or drop all undesired columns.\n\n```python\ndf.drop([c for c in df.columns if c.startswith('temp_')], axis=1, inplace=True)\n// or\ndf = df[[c for c in df.columns if not c.startswith('temp_')]]\n```\n\nWhile this works, it feels bloated and inefficient.\nYou have to prefix all the value names in the code which results in bloated column names.\nYou also have to keep track of column names you want in the end\nor the used prefix in different places.\nJust imagine you have to change the prefix `temp_` one day or make the code work with a different prefix.\n\n## Clean and easy: using a Context Manager\n\nAfter having used the above methods for some time, it struck me that [Python Context Managers](https://jeffknupp.com/blog/2016/03/07/python-with-context-managers/) might be a cleaner solution.\nYou might know them from their most popular application `with open() as file:`.\nIf not, please take a few minutes to read more about them.\nTo make things short: They basically ensure that something, usually a cleanup, is executed in each exit scenario,\nwhether it is a usual exit like a return or an exception.\nI thought I might use this to build a clean solution that keeps track and gets rid of temporary columns.\nSo I built a Context Manager that deals with temporary columns when importing JSON data so I don't have to.\nYou can basically use it like this:\n\n```python\nwith DataFrameFromDict(companies) as df:\n    // imported dict now in df, same result as json_normalize\n    df['company_id'] = df['companyId']\n    df['location'] = df['properties.city.value']\n    df['name'] = df['properties.name.value']\n    df['domain'] = df['properties.website.value']\n// after context exits, df contains company_id, location, name, and domain\n// but no more temporary columns\nprint(df)\n```\n\nThe benefit: You don't have to keep track anymore and the context manager handles the deletion of all temporary columns.\n\n## How it works\n\nYou can just copy and paste the following snippet to get going, I'll explain how it works below:\n\n```python\nclass DataFrameFromDict(object):\n    \"\"\"\n    Temporarily imports data frame columns and deletes them afterwards.\n    \"\"\"\n\n    def __init__(self, data):\n        self.df = json_normalize(data)\n        self.columns = list(self.df.columns.values)\n\n    def __enter__(self):\n        return self.df\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        self.df.drop([c for c in self.columns], axis=1, inplace=True)\n```\n\nWhen opening the context, `__init__` and `__enter__` get called.\nThey create the DataFrame and remember all imported and thus temporary column names.\nWhen the context is exited, `__exit__` makes sure to drop all previously created columns\nand leaves only the newly created columns behind.\n\nHope this helps you to create a clean pre-processing pipeline.\nLet me know what you think.\nYou can find the [code on GitHub](https://gist.github.com/lorey/2b57b4ebfec4d45221e15a49060f80d2).\n\nFurther reading:\n\n- [json_normalize](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.io.json.json_normalize.html)\n- [Python Context Managers](https://jeffknupp.com/blog/2016/03/07/python-with-context-managers/)\n"},"mdxSource":{"compiledSource":"\"use strict\";\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = {\n    a: \"a\",\n    code: \"code\",\n    h2: \"h2\",\n    li: \"li\",\n    p: \"p\",\n    pre: \"pre\",\n    ul: \"ul\",\n    ..._provideComponents(),\n    ...props.components\n  };\n  return _jsxs(_Fragment, {\n    children: [_jsx(_components.p, {\n      children: \"For work, I do a lot of data analysis to find the most promising young startups.\\nAs a first step, you always have to import the desired data into a Pandas DataFrame\\nand do some preprocessing, for example by importing JSON data from some API. \\nWhen doing this kind of pre-processing,\\nyou usually have a lot of temporary columns in your DataFrame that get imported but need to be dropped later in the process.\\nTo deal with these temporary columns,\\nI built a custom Context Manager that keeps track of all imported columns\\nand deletes them when you're done.\\nThis way, your code stays lean and you don't have to remove temporary columns yourself.\\nIn this short article, I will show how you can keep your pre-processing clean\\nand use a Python ContextManager to clean up temporary columns.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"In this example I will use the actual code I use for importing data from the API of our CRM named Hubspot.\\nWhat I retrieve is a list of companies stored as a list of Python dictionaries.\\nTo import a list of dictionaries in pandas you basically do:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-python\",\n        children: \"from pandas.io.json import json_normalize\\n\\ndf = json_normalize(data)\\n\"\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"The json_normalize function generates a clean DataFrame based on the given \", _jsx(_components.code, {\n        children: \"data\"\n      }), \" parameter and normalizes the hierarchy so you get clean column names.\\nThis is especially useful for nested dictionaries.\"]\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"Ugly: Keeping imported columns\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The problem with json_normalize is that you usually only want a subset of the imported columns,\\nmostly with different names or some kind of pre-processing, too.\\nSo you might be tempted to do something like this:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-python\",\n        children: \"from pandas.io.json import json_normalize\\n\\ndf = json_normalize(data)\\n\\ndf['company_id'] = df['companyId']\\ndf['location'] = df['properties.city.value']\\ndf['name'] = df['properties.name.value']\\ndf['domain'] = df['properties.website.value']\\n//..apply(), .as_type(int), whatever...\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"This works, but keeps all the imported columns inplace and might take a lot of storage.\\nSo what can you do?\"\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"Ugly: Dropping columns manually\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"So after importing, you want to get rid of all temporary columns from the import.\\nTo do this, you have to either select the columns you want or drop all columns you don't want.\\nIn both cases, you have to somehow keep track of the temporary columns or the ones you want to keep.\\nTo deal with this, one solution would be to prefix temporary columns and delete them afterwards:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-python\",\n        children: \"from pandas.io.json import json_normalize\\n\\ndf = json_normalize(data)\\n\\n// make temporary columns\\ndf.columns = ['temp_' + c for c in df.columns]\\n\\n// pre-processing, basic calculations, etc.\\ndf['company_id'] = df['temp_companyId']\\ndf['location'] = df['temp_properties.city.value']\\ndf['name'] = df['temp_properties.name.value']\\ndf['domain'] = df['temp_properties.website.value']\\n//..apply(), .as_type(int), whatever...\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Afterwards, you would then select all desired columns or drop all undesired columns.\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-python\",\n        children: \"df.drop([c for c in df.columns if c.startswith('temp_')], axis=1, inplace=True)\\n// or\\ndf = df[[c for c in df.columns if not c.startswith('temp_')]]\\n\"\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"While this works, it feels bloated and inefficient.\\nYou have to prefix all the value names in the code which results in bloated column names.\\nYou also have to keep track of column names you want in the end\\nor the used prefix in different places.\\nJust imagine you have to change the prefix \", _jsx(_components.code, {\n        children: \"temp_\"\n      }), \" one day or make the code work with a different prefix.\"]\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"Clean and easy: using a Context Manager\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"After having used the above methods for some time, it struck me that \", _jsx(_components.a, {\n        href: \"https://jeffknupp.com/blog/2016/03/07/python-with-context-managers/\",\n        children: \"Python Context Managers\"\n      }), \" might be a cleaner solution.\\nYou might know them from their most popular application \", _jsx(_components.code, {\n        children: \"with open() as file:\"\n      }), \".\\nIf not, please take a few minutes to read more about them.\\nTo make things short: They basically ensure that something, usually a cleanup, is executed in each exit scenario,\\nwhether it is a usual exit like a return or an exception.\\nI thought I might use this to build a clean solution that keeps track and gets rid of temporary columns.\\nSo I built a Context Manager that deals with temporary columns when importing JSON data so I don't have to.\\nYou can basically use it like this:\"]\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-python\",\n        children: \"with DataFrameFromDict(companies) as df:\\n    // imported dict now in df, same result as json_normalize\\n    df['company_id'] = df['companyId']\\n    df['location'] = df['properties.city.value']\\n    df['name'] = df['properties.name.value']\\n    df['domain'] = df['properties.website.value']\\n// after context exits, df contains company_id, location, name, and domain\\n// but no more temporary columns\\nprint(df)\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The benefit: You don't have to keep track anymore and the context manager handles the deletion of all temporary columns.\"\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"How it works\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"You can just copy and paste the following snippet to get going, I'll explain how it works below:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-python\",\n        children: \"class DataFrameFromDict(object):\\n    \\\"\\\"\\\"\\n    Temporarily imports data frame columns and deletes them afterwards.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, data):\\n        self.df = json_normalize(data)\\n        self.columns = list(self.df.columns.values)\\n\\n    def __enter__(self):\\n        return self.df\\n\\n    def __exit__(self, exc_type, exc_val, exc_tb):\\n        self.df.drop([c for c in self.columns], axis=1, inplace=True)\\n\"\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"When opening the context, \", _jsx(_components.code, {\n        children: \"__init__\"\n      }), \" and \", _jsx(_components.code, {\n        children: \"__enter__\"\n      }), \" get called.\\nThey create the DataFrame and remember all imported and thus temporary column names.\\nWhen the context is exited, \", _jsx(_components.code, {\n        children: \"__exit__\"\n      }), \" makes sure to drop all previously created columns\\nand leaves only the newly created columns behind.\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Hope this helps you to create a clean pre-processing pipeline.\\nLet me know what you think.\\nYou can find the \", _jsx(_components.a, {\n        href: \"https://gist.github.com/lorey/2b57b4ebfec4d45221e15a49060f80d2\",\n        children: \"code on GitHub\"\n      }), \".\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Further reading:\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: _jsx(_components.a, {\n          href: \"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.io.json.json_normalize.html\",\n          children: \"json_normalize\"\n        })\n      }), \"\\n\", _jsx(_components.li, {\n        children: _jsx(_components.a, {\n          href: \"https://jeffknupp.com/blog/2016/03/07/python-with-context-managers/\",\n          children: \"Python Context Managers\"\n        })\n      }), \"\\n\"]\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = {\n    ..._provideComponents(),\n    ...props.components\n  };\n  return MDXLayout ? _jsx(MDXLayout, {\n    ...props,\n    children: _jsx(_createMdxContent, {\n      ...props\n    })\n  }) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}}},"__N_SSG":true}