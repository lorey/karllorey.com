<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8" data-next-head=""/><meta name="viewport" content="width=device-width" data-next-head=""/><link data-next-font="" rel="preconnect" href="/" crossorigin="anonymous"/><link rel="preload" href="/_next/static/css/56e48dc639721c9d.css" as="style"/><link rel="stylesheet" href="/_next/static/css/56e48dc639721c9d.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" noModule="" src="/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/_next/static/chunks/webpack-8cac0b4b405cede1.js" defer=""></script><script src="/_next/static/chunks/framework-2f335d22a7318891.js" defer=""></script><script src="/_next/static/chunks/main-8b597568282ddf7d.js" defer=""></script><script src="/_next/static/chunks/pages/_app-a3f35041f74c110a.js" defer=""></script><script src="/_next/static/chunks/0465ed09-8f462f33555d06d6.js" defer=""></script><script src="/_next/static/chunks/743-42f317d27b97c576.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bslug%5D-ede33a25f19e577a.js" defer=""></script><script src="/_next/static/uruaTAo3hLOmtwrlFJRkZ/_buildManifest.js" defer=""></script><script src="/_next/static/uruaTAo3hLOmtwrlFJRkZ/_ssgManifest.js" defer=""></script></head><body class="antialiased"><div id="__next"><div class="max-w-xl mx-auto p-5"><header class="text-center py-16"><div class="title py-4"><a href="/">Karl Lorey</a></div><nav class="my-5"><ul class="md:flex justify-center gap-4"><li><a href="/human">Human</a></li><li><a href="/founder">Founder</a></li><li><a href="/portfolio">Maker</a></li><li><a href="/techie">Techie</a></li><li><a href="/vc">Investor</a></li><li><a href="/speaker">Speaker</a></li><li><a href="/blog">Lorey Ipsum</a></li></ul></nav></header><hr class="mb-16"/><h1>Keeping Pandas DataFrames clean when importing JSON (with Context Managers)</h1><div class="text-gray-400 text-sm mb-8">3/3/2019</div><div class="markdown"><p>For work, I do a lot of data analysis to find the most promising young startups.
As a first step, you always have to import the desired data into a Pandas DataFrame
and do some preprocessing, for example by importing JSON data from some API. 
When doing this kind of pre-processing,
you usually have a lot of temporary columns in your DataFrame that get imported but need to be dropped later in the process.
To deal with these temporary columns,
I built a custom Context Manager that keeps track of all imported columns
and deletes them when you&#x27;re done.
This way, your code stays lean and you don&#x27;t have to remove temporary columns yourself.
In this short article, I will show how you can keep your pre-processing clean
and use a Python ContextManager to clean up temporary columns.</p>
<p>In this example I will use the actual code I use for importing data from the API of our CRM named Hubspot.
What I retrieve is a list of companies stored as a list of Python dictionaries.
To import a list of dictionaries in pandas you basically do:</p>
<pre><code class="language-python">from pandas.io.json import json_normalize

df = json_normalize(data)
</code></pre>
<p>The json_normalize function generates a clean DataFrame based on the given <code>data</code> parameter and normalizes the hierarchy so you get clean column names.
This is especially useful for nested dictionaries.</p>
<h2>Ugly: Keeping imported columns</h2>
<p>The problem with json_normalize is that you usually only want a subset of the imported columns,
mostly with different names or some kind of pre-processing, too.
So you might be tempted to do something like this:</p>
<pre><code class="language-python">from pandas.io.json import json_normalize

df = json_normalize(data)

df[&#x27;company_id&#x27;] = df[&#x27;companyId&#x27;]
df[&#x27;location&#x27;] = df[&#x27;properties.city.value&#x27;]
df[&#x27;name&#x27;] = df[&#x27;properties.name.value&#x27;]
df[&#x27;domain&#x27;] = df[&#x27;properties.website.value&#x27;]
//..apply(), .as_type(int), whatever...
</code></pre>
<p>This works, but keeps all the imported columns inplace and might take a lot of storage.
So what can you do?</p>
<h2>Ugly: Dropping columns manually</h2>
<p>So after importing, you want to get rid of all temporary columns from the import.
To do this, you have to either select the columns you want or drop all columns you don&#x27;t want.
In both cases, you have to somehow keep track of the temporary columns or the ones you want to keep.
To deal with this, one solution would be to prefix temporary columns and delete them afterwards:</p>
<pre><code class="language-python">from pandas.io.json import json_normalize

df = json_normalize(data)

// make temporary columns
df.columns = [&#x27;temp_&#x27; + c for c in df.columns]

// pre-processing, basic calculations, etc.
df[&#x27;company_id&#x27;] = df[&#x27;temp_companyId&#x27;]
df[&#x27;location&#x27;] = df[&#x27;temp_properties.city.value&#x27;]
df[&#x27;name&#x27;] = df[&#x27;temp_properties.name.value&#x27;]
df[&#x27;domain&#x27;] = df[&#x27;temp_properties.website.value&#x27;]
//..apply(), .as_type(int), whatever...
</code></pre>
<p>Afterwards, you would then select all desired columns or drop all undesired columns.</p>
<pre><code class="language-python">df.drop([c for c in df.columns if c.startswith(&#x27;temp_&#x27;)], axis=1, inplace=True)
// or
df = df[[c for c in df.columns if not c.startswith(&#x27;temp_&#x27;)]]
</code></pre>
<p>While this works, it feels bloated and inefficient.
You have to prefix all the value names in the code which results in bloated column names.
You also have to keep track of column names you want in the end
or the used prefix in different places.
Just imagine you have to change the prefix <code>temp_</code> one day or make the code work with a different prefix.</p>
<h2>Clean and easy: using a Context Manager</h2>
<p>After having used the above methods for some time, it struck me that <a href="https://jeffknupp.com/blog/2016/03/07/python-with-context-managers/">Python Context Managers</a> might be a cleaner solution.
You might know them from their most popular application <code>with open() as file:</code>.
If not, please take a few minutes to read more about them.
To make things short: They basically ensure that something, usually a cleanup, is executed in each exit scenario,
whether it is a usual exit like a return or an exception.
I thought I might use this to build a clean solution that keeps track and gets rid of temporary columns.
So I built a Context Manager that deals with temporary columns when importing JSON data so I don&#x27;t have to.
You can basically use it like this:</p>
<pre><code class="language-python">with DataFrameFromDict(companies) as df:
    // imported dict now in df, same result as json_normalize
    df[&#x27;company_id&#x27;] = df[&#x27;companyId&#x27;]
    df[&#x27;location&#x27;] = df[&#x27;properties.city.value&#x27;]
    df[&#x27;name&#x27;] = df[&#x27;properties.name.value&#x27;]
    df[&#x27;domain&#x27;] = df[&#x27;properties.website.value&#x27;]
// after context exits, df contains company_id, location, name, and domain
// but no more temporary columns
print(df)
</code></pre>
<p>The benefit: You don&#x27;t have to keep track anymore and the context manager handles the deletion of all temporary columns.</p>
<h2>How it works</h2>
<p>You can just copy and paste the following snippet to get going, I&#x27;ll explain how it works below:</p>
<pre><code class="language-python">class DataFrameFromDict(object):
    &quot;&quot;&quot;
    Temporarily imports data frame columns and deletes them afterwards.
    &quot;&quot;&quot;

    def __init__(self, data):
        self.df = json_normalize(data)
        self.columns = list(self.df.columns.values)

    def __enter__(self):
        return self.df

    def __exit__(self, exc_type, exc_val, exc_tb):
        self.df.drop([c for c in self.columns], axis=1, inplace=True)
</code></pre>
<p>When opening the context, <code>__init__</code> and <code>__enter__</code> get called.
They create the DataFrame and remember all imported and thus temporary column names.
When the context is exited, <code>__exit__</code> makes sure to drop all previously created columns
and leaves only the newly created columns behind.</p>
<p>Hope this helps you to create a clean pre-processing pipeline.
Let me know what you think.
You can find the <a href="https://gist.github.com/lorey/2b57b4ebfec4d45221e15a49060f80d2">code on GitHub</a>.</p>
<p>Further reading:</p>
<ul>
<li><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.io.json.json_normalize.html">json_normalize</a></li>
<li><a href="https://jeffknupp.com/blog/2016/03/07/python-with-context-managers/">Python Context Managers</a></li>
</ul></div><hr class="my-16"/><footer class="text-center text-sm py-10"><p class="">I&#x27;m Karl Lorey–Techie, Founder, and Investor living in Karlsruhe, Germany.<br/>Let&#x27;s get in touch.</p><p class="flex justify-center gap-5 flex-wrap text-xl"><a href="https://angel.co/karllorey" target="_blank"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" class="inline" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M347.1 215.4c11.7-32.6 45.4-126.9 45.4-157.1 0-26.6-15.7-48.9-43.7-48.9-44.6 0-84.6 131.7-97.1 163.1C242 144 196.6 0 156.6 0c-31.1 0-45.7 22.9-45.7 51.7 0 35.3 34.2 126.8 46.6 162-6.3-2.3-13.1-4.3-20-4.3-23.4 0-48.3 29.1-48.3 52.6 0 8.9 4.9 21.4 8 29.7-36.9 10-51.1 34.6-51.1 71.7C46 435.6 114.4 512 210.6 512c118 0 191.4-88.6 191.4-202.9 0-43.1-6.9-82-54.9-93.7zM311.7 108c4-12.3 21.1-64.3 37.1-64.3 8.6 0 10.9 8.9 10.9 16 0 19.1-38.6 124.6-47.1 148l-34-6 33.1-93.7zM142.3 48.3c0-11.9 14.5-45.7 46.3 47.1l34.6 100.3c-15.6-1.3-27.7-3-35.4 1.4-10.9-28.8-45.5-119.7-45.5-148.8zM140 244c29.3 0 67.1 94.6 67.1 107.4 0 5.1-4.9 11.4-10.6 11.4-20.9 0-76.9-76.9-76.9-97.7.1-7.7 12.7-21.1 20.4-21.1zm184.3 186.3c-29.1 32-66.3 48.6-109.7 48.6-59.4 0-106.3-32.6-128.9-88.3-17.1-43.4 3.8-68.3 20.6-68.3 11.4 0 54.3 60.3 54.3 73.1 0 4.9-7.7 8.3-11.7 8.3-16.1 0-22.4-15.5-51.1-51.4-29.7 29.7 20.5 86.9 58.3 86.9 26.1 0 43.1-24.2 38-42 3.7 0 8.3.3 11.7-.6 1.1 27.1 9.1 59.4 41.7 61.7 0-.9 2-7.1 2-7.4 0-17.4-10.6-32.6-10.6-50.3 0-28.3 21.7-55.7 43.7-71.7 8-6 17.7-9.7 27.1-13.1 9.7-3.7 20-8 27.4-15.4-1.1-11.2-5.7-21.1-16.9-21.1-27.7 0-120.6 4-120.6-39.7 0-6.7.1-13.1 17.4-13.1 32.3 0 114.3 8 138.3 29.1 18.1 16.1 24.3 113.2-31 174.7zm-98.6-126c9.7 3.1 19.7 4 29.7 6-7.4 5.4-14 12-20.3 19.1-2.8-8.5-6.2-16.8-9.4-25.1z"></path></svg></a><a href="https://www.crunchbase.com/person/karl-lorey" target="_blank"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" class="inline" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M239.1 6.3l-208 78c-18.7 7-31.1 25-31.1 45v225.1c0 18.2 10.3 34.8 26.5 42.9l208 104c13.5 6.8 29.4 6.8 42.9 0l208-104c16.3-8.1 26.5-24.8 26.5-42.9V129.3c0-20-12.4-37.9-31.1-44.9l-208-78C262 2.2 250 2.2 239.1 6.3zM256 68.4l192 72v1.1l-192 78-192-78v-1.1l192-72zm32 356V275.5l160-65v133.9l-160 80z"></path></svg></a><a href="https://github.com/lorey" target="_blank"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" class="inline" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a><a href="https://gitlab.com/lorey" target="_blank"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" class="inline" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M105.2 24.9c-3.1-8.9-15.7-8.9-18.9 0L29.8 199.7h132c-.1 0-56.6-174.8-56.6-174.8zM.9 287.7c-2.6 8 .3 16.9 7.1 22l247.9 184-226.2-294zm160.8-88l94.3 294 94.3-294zm349.4 88l-28.8-88-226.3 294 247.9-184c6.9-5.1 9.7-14 7.2-22zM425.7 24.9c-3.1-8.9-15.7-8.9-18.9 0l-56.6 174.8h132z"></path></svg></a><a href="https://www.goodreads.com/karllorey" target="_blank"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" class="inline" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M299.9 191.2c5.1 37.3-4.7 79-35.9 100.7-22.3 15.5-52.8 14.1-70.8 5.7-37.1-17.3-49.5-58.6-46.8-97.2 4.3-60.9 40.9-87.9 75.3-87.5 46.9-.2 71.8 31.8 78.2 78.3zM448 88v336c0 30.9-25.1 56-56 56H56c-30.9 0-56-25.1-56-56V88c0-30.9 25.1-56 56-56h336c30.9 0 56 25.1 56 56zM330 313.2s-.1-34-.1-217.3h-29v40.3c-.8.3-1.2-.5-1.6-1.2-9.6-20.7-35.9-46.3-76-46-51.9.4-87.2 31.2-100.6 77.8-4.3 14.9-5.8 30.1-5.5 45.6 1.7 77.9 45.1 117.8 112.4 115.2 28.9-1.1 54.5-17 69-45.2.5-1 1.1-1.9 1.7-2.9.2.1.4.1.6.2.3 3.8.2 30.7.1 34.5-.2 14.8-2 29.5-7.2 43.5-7.8 21-22.3 34.7-44.5 39.5-17.8 3.9-35.6 3.8-53.2-1.2-21.5-6.1-36.5-19-41.1-41.8-.3-1.6-1.3-1.3-2.3-1.3h-26.8c.8 10.6 3.2 20.3 8.5 29.2 24.2 40.5 82.7 48.5 128.2 37.4 49.9-12.3 67.3-54.9 67.4-106.3z"></path></svg></a><a href="https://www.instagram.com/karllorey" target="_blank"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" class="inline" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M224.1 141c-63.6 0-114.9 51.3-114.9 114.9s51.3 114.9 114.9 114.9S339 319.5 339 255.9 287.7 141 224.1 141zm0 189.6c-41.1 0-74.7-33.5-74.7-74.7s33.5-74.7 74.7-74.7 74.7 33.5 74.7 74.7-33.6 74.7-74.7 74.7zm146.4-194.3c0 14.9-12 26.8-26.8 26.8-14.9 0-26.8-12-26.8-26.8s12-26.8 26.8-26.8 26.8 12 26.8 26.8zm76.1 27.2c-1.7-35.9-9.9-67.7-36.2-93.9-26.2-26.2-58-34.4-93.9-36.2-37-2.1-147.9-2.1-184.9 0-35.8 1.7-67.6 9.9-93.9 36.1s-34.4 58-36.2 93.9c-2.1 37-2.1 147.9 0 184.9 1.7 35.9 9.9 67.7 36.2 93.9s58 34.4 93.9 36.2c37 2.1 147.9 2.1 184.9 0 35.9-1.7 67.7-9.9 93.9-36.2 26.2-26.2 34.4-58 36.2-93.9 2.1-37 2.1-147.8 0-184.8zM398.8 388c-7.8 19.6-22.9 34.7-42.6 42.6-29.5 11.7-99.5 9-132.1 9s-102.7 2.6-132.1-9c-19.6-7.8-34.7-22.9-42.6-42.6-11.7-29.5-9-99.5-9-132.1s-2.6-102.7 9-132.1c7.8-19.6 22.9-34.7 42.6-42.6 29.5-11.7 99.5-9 132.1-9s102.7-2.6 132.1 9c19.6 7.8 34.7 22.9 42.6 42.6 11.7 29.5 9 99.5 9 132.1s2.7 102.7-9 132.1z"></path></svg></a><a href="https://www.linkedin.com/in/karllorey" target="_blank"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" class="inline" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"></path></svg></a><a href="https://medium.com/@karllorey" target="_blank"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" class="inline" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 32v448h448V32H0zm372.2 106.1l-24 23c-2.1 1.6-3.1 4.2-2.7 6.7v169.3c-.4 2.6.6 5.2 2.7 6.7l23.5 23v5.1h-118V367l24.3-23.6c2.4-2.4 2.4-3.1 2.4-6.7V199.8l-67.6 171.6h-9.1L125 199.8v115c-.7 4.8 1 9.7 4.4 13.2l31.6 38.3v5.1H71.2v-5.1l31.6-38.3c3.4-3.5 4.9-8.4 4.1-13.2v-133c.4-3.7-1-7.3-3.8-9.8L75 138.1V133h87.3l67.4 148L289 133.1h83.2v5z"></path></svg></a><a href="https://www.meetup.com/members/196097665/" target="_blank"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" class="inline" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M99 414.3c1.1 5.7-2.3 11.1-8 12.3-5.4 1.1-10.9-2.3-12-8-1.1-5.4 2.3-11.1 7.7-12.3 5.4-1.2 11.1 2.3 12.3 8zm143.1 71.4c-6.3 4.6-8 13.4-3.7 20 4.6 6.6 13.4 8.3 20 3.7 6.3-4.6 8-13.4 3.4-20-4.2-6.5-13.1-8.3-19.7-3.7zm-86-462.3c6.3-1.4 10.3-7.7 8.9-14-1.1-6.6-7.4-10.6-13.7-9.1-6.3 1.4-10.3 7.7-9.1 14 1.4 6.6 7.6 10.6 13.9 9.1zM34.4 226.3c-10-6.9-23.7-4.3-30.6 6-6.9 10-4.3 24 5.7 30.9 10 7.1 23.7 4.6 30.6-5.7 6.9-10.4 4.3-24.1-5.7-31.2zm272-170.9c10.6-6.3 13.7-20 7.7-30.3-6.3-10.6-19.7-14-30-7.7s-13.7 20-7.4 30.6c6 10.3 19.4 13.7 29.7 7.4zm-191.1 58c7.7-5.4 9.4-16 4.3-23.7s-15.7-9.4-23.1-4.3c-7.7 5.4-9.4 16-4.3 23.7 5.1 7.8 15.6 9.5 23.1 4.3zm372.3 156c-7.4 1.7-12.3 9.1-10.6 16.9 1.4 7.4 8.9 12.3 16.3 10.6 7.4-1.4 12.3-8.9 10.6-16.6-1.5-7.4-8.9-12.3-16.3-10.9zm39.7-56.8c-1.1-5.7-6.6-9.1-12-8-5.7 1.1-9.1 6.9-8 12.6 1.1 5.4 6.6 9.1 12.3 8 5.4-1.5 9.1-6.9 7.7-12.6zM447 138.9c-8.6 6-10.6 17.7-4.9 26.3 5.7 8.6 17.4 10.6 26 4.9 8.3-6 10.3-17.7 4.6-26.3-5.7-8.7-17.4-10.9-25.7-4.9zm-6.3 139.4c26.3 43.1 15.1 100-26.3 129.1-17.4 12.3-37.1 17.7-56.9 17.1-12 47.1-69.4 64.6-105.1 32.6-1.1.9-2.6 1.7-3.7 2.9-39.1 27.1-92.3 17.4-119.4-22.3-9.7-14.3-14.6-30.6-15.1-46.9-65.4-10.9-90-94-41.1-139.7-28.3-46.9.6-107.4 53.4-114.9C151.6 70 234.1 38.6 290.1 82c67.4-22.3 136.3 29.4 130.9 101.1 41.1 12.6 52.8 66.9 19.7 95.2zm-70 74.3c-3.1-20.6-40.9-4.6-43.1-27.1-3.1-32 43.7-101.1 40-128-3.4-24-19.4-29.1-33.4-29.4-13.4-.3-16.9 2-21.4 4.6-2.9 1.7-6.6 4.9-11.7-.3-6.3-6-11.1-11.7-19.4-12.9-12.3-2-17.7 2-26.6 9.7-3.4 2.9-12 12.9-20 9.1-3.4-1.7-15.4-7.7-24-11.4-16.3-7.1-40 4.6-48.6 20-12.9 22.9-38 113.1-41.7 125.1-8.6 26.6 10.9 48.6 36.9 47.1 11.1-.6 18.3-4.6 25.4-17.4 4-7.4 41.7-107.7 44.6-112.6 2-3.4 8.9-8 14.6-5.1 5.7 3.1 6.9 9.4 6 15.1-1.1 9.7-28 70.9-28.9 77.7-3.4 22.9 26.9 26.6 38.6 4 3.7-7.1 45.7-92.6 49.4-98.3 4.3-6.3 7.4-8.3 11.7-8 3.1 0 8.3.9 7.1 10.9-1.4 9.4-35.1 72.3-38.9 87.7-4.6 20.6 6.6 41.4 24.9 50.6 11.4 5.7 62.5 15.7 58.5-11.1zm5.7 92.3c-10.3 7.4-12.9 22-5.7 32.6 7.1 10.6 21.4 13.1 32 6 10.6-7.4 13.1-22 6-32.6-7.4-10.6-21.7-13.5-32.3-6z"></path></svg></a><a href="https://www.producthunt.com/@karllorey" target="_blank"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" class="inline" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M326.3 218.8c0 20.5-16.7 37.2-37.2 37.2h-70.3v-74.4h70.3c20.5 0 37.2 16.7 37.2 37.2zM504 256c0 137-111 248-248 248S8 393 8 256 119 8 256 8s248 111 248 248zm-128.1-37.2c0-47.9-38.9-86.8-86.8-86.8H169.2v248h49.6v-74.4h70.3c47.9 0 86.8-38.9 86.8-86.8z"></path></svg></a><a href="https://www.researchgate.net/profile/Karl_Lorey" target="_blank"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" class="inline" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 32v448h448V32H0zm262.2 334.4c-6.6 3-33.2 6-50-14.2-9.2-10.6-25.3-33.3-42.2-63.6-8.9 0-14.7 0-21.4-.6v46.4c0 23.5 6 21.2 25.8 23.9v8.1c-6.9-.3-23.1-.8-35.6-.8-13.1 0-26.1.6-33.6.8v-8.1c15.5-2.9 22-1.3 22-23.9V225c0-22.6-6.4-21-22-23.9V193c25.8 1 53.1-.6 70.9-.6 31.7 0 55.9 14.4 55.9 45.6 0 21.1-16.7 42.2-39.2 47.5 13.6 24.2 30 45.6 42.2 58.9 7.2 7.8 17.2 14.7 27.2 14.7v7.3zm22.9-135c-23.3 0-32.2-15.7-32.2-32.2V167c0-12.2 8.8-30.4 34-30.4s30.4 17.9 30.4 17.9l-10.7 7.2s-5.5-12.5-19.7-12.5c-7.9 0-19.7 7.3-19.7 19.7v26.8c0 13.4 6.6 23.3 17.9 23.3 14.1 0 21.5-10.9 21.5-26.8h-17.9v-10.7h30.4c0 20.5 4.7 49.9-34 49.9zm-116.5 44.7c-9.4 0-13.6-.3-20-.8v-69.7c6.4-.6 15-.6 22.5-.6 23.3 0 37.2 12.2 37.2 34.5 0 21.9-15 36.6-39.7 36.6z"></path></svg></a><a href="https://twitter.com/karllorey" target="_blank"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" class="inline" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"></path></svg></a></p><p class="mt-5">This site does not use cookies or other services to improve your experience. No data is stored. It is released as<!-- --> <a href="https://github.com/lorey/karllorey.com">Open Source on Github</a>.</p><p class="mt-5">© Copyright 2025 Karl Lorey.<br/><a href="/legal">Legal/Imprint</a>.<!-- --> <a href="/privacy">Privacy Policy</a>.</p></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"Keeping Pandas DataFrames clean when importing JSON (with Context Managers)","slug":"keeping-pandas-dataframes-clean-importing-json","date":"2019-03-03T09:30:13.000Z","tags":"Machine Learning, Pandas, Clean Code, Python, Tech","category":"Tech","link":null,"description":null,"type":"text","content":"\nFor work, I do a lot of data analysis to find the most promising young startups.\nAs a first step, you always have to import the desired data into a Pandas DataFrame\nand do some preprocessing, for example by importing JSON data from some API. \nWhen doing this kind of pre-processing,\nyou usually have a lot of temporary columns in your DataFrame that get imported but need to be dropped later in the process.\nTo deal with these temporary columns,\nI built a custom Context Manager that keeps track of all imported columns\nand deletes them when you're done.\nThis way, your code stays lean and you don't have to remove temporary columns yourself.\nIn this short article, I will show how you can keep your pre-processing clean\nand use a Python ContextManager to clean up temporary columns.\n\nIn this example I will use the actual code I use for importing data from the API of our CRM named Hubspot.\nWhat I retrieve is a list of companies stored as a list of Python dictionaries.\nTo import a list of dictionaries in pandas you basically do:\n\n```python\nfrom pandas.io.json import json_normalize\n\ndf = json_normalize(data)\n```\n\nThe json_normalize function generates a clean DataFrame based on the given `data` parameter and normalizes the hierarchy so you get clean column names.\nThis is especially useful for nested dictionaries.\n\n## Ugly: Keeping imported columns\n\nThe problem with json_normalize is that you usually only want a subset of the imported columns,\nmostly with different names or some kind of pre-processing, too.\nSo you might be tempted to do something like this:\n\n```python\nfrom pandas.io.json import json_normalize\n\ndf = json_normalize(data)\n\ndf['company_id'] = df['companyId']\ndf['location'] = df['properties.city.value']\ndf['name'] = df['properties.name.value']\ndf['domain'] = df['properties.website.value']\n//..apply(), .as_type(int), whatever...\n```\n\nThis works, but keeps all the imported columns inplace and might take a lot of storage.\nSo what can you do?\n\n## Ugly: Dropping columns manually\n\nSo after importing, you want to get rid of all temporary columns from the import.\nTo do this, you have to either select the columns you want or drop all columns you don't want.\nIn both cases, you have to somehow keep track of the temporary columns or the ones you want to keep.\nTo deal with this, one solution would be to prefix temporary columns and delete them afterwards:\n\n```python\nfrom pandas.io.json import json_normalize\n\ndf = json_normalize(data)\n\n// make temporary columns\ndf.columns = ['temp_' + c for c in df.columns]\n\n// pre-processing, basic calculations, etc.\ndf['company_id'] = df['temp_companyId']\ndf['location'] = df['temp_properties.city.value']\ndf['name'] = df['temp_properties.name.value']\ndf['domain'] = df['temp_properties.website.value']\n//..apply(), .as_type(int), whatever...\n```\n\nAfterwards, you would then select all desired columns or drop all undesired columns.\n\n```python\ndf.drop([c for c in df.columns if c.startswith('temp_')], axis=1, inplace=True)\n// or\ndf = df[[c for c in df.columns if not c.startswith('temp_')]]\n```\n\nWhile this works, it feels bloated and inefficient.\nYou have to prefix all the value names in the code which results in bloated column names.\nYou also have to keep track of column names you want in the end\nor the used prefix in different places.\nJust imagine you have to change the prefix `temp_` one day or make the code work with a different prefix.\n\n## Clean and easy: using a Context Manager\n\nAfter having used the above methods for some time, it struck me that [Python Context Managers](https://jeffknupp.com/blog/2016/03/07/python-with-context-managers/) might be a cleaner solution.\nYou might know them from their most popular application `with open() as file:`.\nIf not, please take a few minutes to read more about them.\nTo make things short: They basically ensure that something, usually a cleanup, is executed in each exit scenario,\nwhether it is a usual exit like a return or an exception.\nI thought I might use this to build a clean solution that keeps track and gets rid of temporary columns.\nSo I built a Context Manager that deals with temporary columns when importing JSON data so I don't have to.\nYou can basically use it like this:\n\n```python\nwith DataFrameFromDict(companies) as df:\n    // imported dict now in df, same result as json_normalize\n    df['company_id'] = df['companyId']\n    df['location'] = df['properties.city.value']\n    df['name'] = df['properties.name.value']\n    df['domain'] = df['properties.website.value']\n// after context exits, df contains company_id, location, name, and domain\n// but no more temporary columns\nprint(df)\n```\n\nThe benefit: You don't have to keep track anymore and the context manager handles the deletion of all temporary columns.\n\n## How it works\n\nYou can just copy and paste the following snippet to get going, I'll explain how it works below:\n\n```python\nclass DataFrameFromDict(object):\n    \"\"\"\n    Temporarily imports data frame columns and deletes them afterwards.\n    \"\"\"\n\n    def __init__(self, data):\n        self.df = json_normalize(data)\n        self.columns = list(self.df.columns.values)\n\n    def __enter__(self):\n        return self.df\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        self.df.drop([c for c in self.columns], axis=1, inplace=True)\n```\n\nWhen opening the context, `__init__` and `__enter__` get called.\nThey create the DataFrame and remember all imported and thus temporary column names.\nWhen the context is exited, `__exit__` makes sure to drop all previously created columns\nand leaves only the newly created columns behind.\n\nHope this helps you to create a clean pre-processing pipeline.\nLet me know what you think.\nYou can find the [code on GitHub](https://gist.github.com/lorey/2b57b4ebfec4d45221e15a49060f80d2).\n\nFurther reading:\n\n- [json_normalize](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.io.json.json_normalize.html)\n- [Python Context Managers](https://jeffknupp.com/blog/2016/03/07/python-with-context-managers/)\n"},"mdxSource":{"compiledSource":"\"use strict\";\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = {\n    a: \"a\",\n    code: \"code\",\n    h2: \"h2\",\n    li: \"li\",\n    p: \"p\",\n    pre: \"pre\",\n    ul: \"ul\",\n    ..._provideComponents(),\n    ...props.components\n  };\n  return _jsxs(_Fragment, {\n    children: [_jsx(_components.p, {\n      children: \"For work, I do a lot of data analysis to find the most promising young startups.\\nAs a first step, you always have to import the desired data into a Pandas DataFrame\\nand do some preprocessing, for example by importing JSON data from some API. \\nWhen doing this kind of pre-processing,\\nyou usually have a lot of temporary columns in your DataFrame that get imported but need to be dropped later in the process.\\nTo deal with these temporary columns,\\nI built a custom Context Manager that keeps track of all imported columns\\nand deletes them when you're done.\\nThis way, your code stays lean and you don't have to remove temporary columns yourself.\\nIn this short article, I will show how you can keep your pre-processing clean\\nand use a Python ContextManager to clean up temporary columns.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"In this example I will use the actual code I use for importing data from the API of our CRM named Hubspot.\\nWhat I retrieve is a list of companies stored as a list of Python dictionaries.\\nTo import a list of dictionaries in pandas you basically do:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-python\",\n        children: \"from pandas.io.json import json_normalize\\n\\ndf = json_normalize(data)\\n\"\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"The json_normalize function generates a clean DataFrame based on the given \", _jsx(_components.code, {\n        children: \"data\"\n      }), \" parameter and normalizes the hierarchy so you get clean column names.\\nThis is especially useful for nested dictionaries.\"]\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"Ugly: Keeping imported columns\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The problem with json_normalize is that you usually only want a subset of the imported columns,\\nmostly with different names or some kind of pre-processing, too.\\nSo you might be tempted to do something like this:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-python\",\n        children: \"from pandas.io.json import json_normalize\\n\\ndf = json_normalize(data)\\n\\ndf['company_id'] = df['companyId']\\ndf['location'] = df['properties.city.value']\\ndf['name'] = df['properties.name.value']\\ndf['domain'] = df['properties.website.value']\\n//..apply(), .as_type(int), whatever...\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"This works, but keeps all the imported columns inplace and might take a lot of storage.\\nSo what can you do?\"\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"Ugly: Dropping columns manually\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"So after importing, you want to get rid of all temporary columns from the import.\\nTo do this, you have to either select the columns you want or drop all columns you don't want.\\nIn both cases, you have to somehow keep track of the temporary columns or the ones you want to keep.\\nTo deal with this, one solution would be to prefix temporary columns and delete them afterwards:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-python\",\n        children: \"from pandas.io.json import json_normalize\\n\\ndf = json_normalize(data)\\n\\n// make temporary columns\\ndf.columns = ['temp_' + c for c in df.columns]\\n\\n// pre-processing, basic calculations, etc.\\ndf['company_id'] = df['temp_companyId']\\ndf['location'] = df['temp_properties.city.value']\\ndf['name'] = df['temp_properties.name.value']\\ndf['domain'] = df['temp_properties.website.value']\\n//..apply(), .as_type(int), whatever...\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Afterwards, you would then select all desired columns or drop all undesired columns.\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-python\",\n        children: \"df.drop([c for c in df.columns if c.startswith('temp_')], axis=1, inplace=True)\\n// or\\ndf = df[[c for c in df.columns if not c.startswith('temp_')]]\\n\"\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"While this works, it feels bloated and inefficient.\\nYou have to prefix all the value names in the code which results in bloated column names.\\nYou also have to keep track of column names you want in the end\\nor the used prefix in different places.\\nJust imagine you have to change the prefix \", _jsx(_components.code, {\n        children: \"temp_\"\n      }), \" one day or make the code work with a different prefix.\"]\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"Clean and easy: using a Context Manager\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"After having used the above methods for some time, it struck me that \", _jsx(_components.a, {\n        href: \"https://jeffknupp.com/blog/2016/03/07/python-with-context-managers/\",\n        children: \"Python Context Managers\"\n      }), \" might be a cleaner solution.\\nYou might know them from their most popular application \", _jsx(_components.code, {\n        children: \"with open() as file:\"\n      }), \".\\nIf not, please take a few minutes to read more about them.\\nTo make things short: They basically ensure that something, usually a cleanup, is executed in each exit scenario,\\nwhether it is a usual exit like a return or an exception.\\nI thought I might use this to build a clean solution that keeps track and gets rid of temporary columns.\\nSo I built a Context Manager that deals with temporary columns when importing JSON data so I don't have to.\\nYou can basically use it like this:\"]\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-python\",\n        children: \"with DataFrameFromDict(companies) as df:\\n    // imported dict now in df, same result as json_normalize\\n    df['company_id'] = df['companyId']\\n    df['location'] = df['properties.city.value']\\n    df['name'] = df['properties.name.value']\\n    df['domain'] = df['properties.website.value']\\n// after context exits, df contains company_id, location, name, and domain\\n// but no more temporary columns\\nprint(df)\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The benefit: You don't have to keep track anymore and the context manager handles the deletion of all temporary columns.\"\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"How it works\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"You can just copy and paste the following snippet to get going, I'll explain how it works below:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-python\",\n        children: \"class DataFrameFromDict(object):\\n    \\\"\\\"\\\"\\n    Temporarily imports data frame columns and deletes them afterwards.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, data):\\n        self.df = json_normalize(data)\\n        self.columns = list(self.df.columns.values)\\n\\n    def __enter__(self):\\n        return self.df\\n\\n    def __exit__(self, exc_type, exc_val, exc_tb):\\n        self.df.drop([c for c in self.columns], axis=1, inplace=True)\\n\"\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"When opening the context, \", _jsx(_components.code, {\n        children: \"__init__\"\n      }), \" and \", _jsx(_components.code, {\n        children: \"__enter__\"\n      }), \" get called.\\nThey create the DataFrame and remember all imported and thus temporary column names.\\nWhen the context is exited, \", _jsx(_components.code, {\n        children: \"__exit__\"\n      }), \" makes sure to drop all previously created columns\\nand leaves only the newly created columns behind.\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Hope this helps you to create a clean pre-processing pipeline.\\nLet me know what you think.\\nYou can find the \", _jsx(_components.a, {\n        href: \"https://gist.github.com/lorey/2b57b4ebfec4d45221e15a49060f80d2\",\n        children: \"code on GitHub\"\n      }), \".\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Further reading:\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: _jsx(_components.a, {\n          href: \"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.io.json.json_normalize.html\",\n          children: \"json_normalize\"\n        })\n      }), \"\\n\", _jsx(_components.li, {\n        children: _jsx(_components.a, {\n          href: \"https://jeffknupp.com/blog/2016/03/07/python-with-context-managers/\",\n          children: \"Python Context Managers\"\n        })\n      }), \"\\n\"]\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = {\n    ..._provideComponents(),\n    ...props.components\n  };\n  return MDXLayout ? _jsx(MDXLayout, {\n    ...props,\n    children: _jsx(_createMdxContent, {\n      ...props\n    })\n  }) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}}},"__N_SSG":true},"page":"/posts/[slug]","query":{"slug":"keeping-pandas-dataframes-clean-importing-json"},"buildId":"uruaTAo3hLOmtwrlFJRkZ","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>